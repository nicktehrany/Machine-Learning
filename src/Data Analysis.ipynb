{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/nicktehrany/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/nicktehrany/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # for loading data\n",
    "import scipy.stats as stats\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter # For counting word frequencies\n",
    "import re # for removing special characters\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords # For removing stopwords\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "odf = pd.read_csv('songs_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "odf_genre_count = odf['Genre'].value_counts()\n",
    "#print(odf_genre_count)\n",
    "odf_genre_count = odf_genre_count[0:15]\n",
    "#odf_genre_count.plot(kind=\"bar\", title=\"Original Dataset Genre Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf = pd.read_csv('dataset.csv')\n",
    "edf_genre_count = edf['Genre'].value_counts()\n",
    "#print(odf_genre_count)\n",
    "#edf_genre_count.plot(kind=\"bar\", title=\"New Dataset Genre Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Lyrics (Lemmatizing, etc..) and counting each words frequency (Only for the first ten songs right now) **Has dropping of words with frequency count below a certain number**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'killer': 31, 'fuck': 16, 'nine': 13, 'gon': 12, 'cock': 12, 'kill': 12, 'motherfucker': 12, 'mane': 5, 'ring': 4, 'bitch': 3, 'hoe': 3, 'chain': 2, 'cause': 2, 'go': 2, 'store': 2, 'leave': 2, 'blow': 2, 'bag': 2, 'like': 2, 'get': 2, 'phone': 2, 'live': 2, 'nowmane': 1, 'fifty': 1, 'shade': 1, 'grey': 1, 'still': 1, 'glow': 1, 'shin': 1, 'diamond': 1, 'birthstone': 1, 'change': 1, 'dope': 1, 'cocaine': 1, 'look': 1, 'crow': 1, 'kick': 1, 'brandon': 1, 'blood': 1, 'ice': 1, 'cold': 1, 'vein': 1, 'carecrow': 1, 'make': 1, 'escrow': 1, 'gain': 1, 'pimp': 1, 'freeze': 1, 'old': 1, 'black': 1, 'mustang': 1, 'alone': 1, 'yesterday': 1, 'ride': 1, 'bike': 1, 'moon': 1, 'think': 1, 'trippin': 1, 'shrooms': 1, 'smoke': 1, 'pcp': 1, 'crimmy': 1, 'mentally': 1, 'penitentiary': 1, 'meth': 1, 'lab': 1, 'chemistry': 1, 'heisenberg': 1, 'burbs': 1, 'talk': 1, 'slur': 1, 'bird': 1, 'kickin': 1, 'curb': 1, 'yung': 1, 'christ': 1, 'save': 1, 'world': 1, 'crucify': 1, 'upside': 1, 'rotten': 1, 'nail': 1, 'move': 1, 'snail': 1, 'drink': 1, 'lean': 1, 'ginger': 1, 'ale': 1, 'police': 1, 'tail': 1, 'couple': 1, 'goonies': 1, 'jail': 1, 'hell': 1, 'chillin': 1, 'well': 1, 'rather': 1, 'roll': 1, 'six': 1, 'feet': 1, 'dirt': 1, 'bury': 1, 'know': 1, 'squirt': 1, 'ho': 1, 'oh': 1, 'harder': 1})\n",
      "Counter({'killer': 31, 'fuck': 16, 'nine': 13, 'gon': 12, 'cock': 12, 'kill': 12, 'motherfucker': 12, 'mane': 5, 'ring': 4, 'bitch': 3, 'hoe': 3})\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "lyrics = edf['Lyrics']\n",
    "sw = stopwords.words(\"english\")\n",
    "for i in range(0, 1):\n",
    "    text = re.sub('[^a-zA-Z]', ' ', str(lyrics[i])) # removes special characters\n",
    "    text = text.lower() # lowercases everything\n",
    "    text = text.split() # splits words\n",
    "    text = [wordnet_lemmatizer.lemmatize(word, pos=\"v\") for word in text if not word in set(sw)]\n",
    "    corpus.append(text)\n",
    "    \n",
    "    #Removes all words occuting less than 3 times\n",
    "    counts = Counter(text)\n",
    "    print(counts)\n",
    "    index = 0\n",
    "    for words in counts:\n",
    "        if list(counts.values())[index] < 3:\n",
    "            text = list(filter((list(counts.keys())[index]).__ne__, text))\n",
    "        index += 1\n",
    "    counts = Counter(text)\n",
    "    print(counts)\n",
    "# lyrics = corpus\n",
    "# for text in lyrics:\n",
    "#     counts = Counter(text)\n",
    "#     print(counts.most_common(20))\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Analysis on the release dates of the songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_count = edf['Date'].value_counts()\n",
    "#print(date_count)\n",
    "# date_count[0:20].plot(kind=\"bar\", color=\"red\", title=\"Genre\")\n",
    "singer_count = edf['Singer'].value_counts()\n",
    "#print(singer_count)\n",
    "#singer_count[0:20].plot(kind=\"bar\", color=\"red\", title=\"Singers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
