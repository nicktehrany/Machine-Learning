{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/paul/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/paul/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # for loading data\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import re # for removing special characters\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "import nltk\n",
    "import random\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords # For removing stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/paulp/Desktop/machine learning\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/paul/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/paul/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/paul/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/paul/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/paul/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/paul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/paul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/paul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/paul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/paul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/paul/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "[nltk_data] Downloading package wordnet to /home/paul/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/paul/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from util.helperfunctions import clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/paulp/Desktop/machine learning/src\n"
     ]
    }
   ],
   "source": [
    "cd src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = pd.read_csv(\"validation.csv\")\n",
    "lyrics_val, dummy_list = clean_text(validation_df['Lyrics'], 0)\n",
    "genre_val = validation_df['Genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "lyrics_train, dummy_list= clean_text(train_df['Lyrics'], 0)\n",
    "genre_train = train_df['Genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "lyrics_test, dummy_list = clean_text(test_df['Lyrics'], 0)\n",
    "genre_test = test_df['Genre']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using a count vectorizer gave us better results than actually using the TFIDF formula we hypothesize that normalizing the frequently used terms is actually not desirable with so many classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df = 3)\n",
    "train_data_tfid = vectorizer.fit_transform(lyrics_train).toarray()\n",
    "test_data = vectorizer.transform(lyrics_test).toarray()\n",
    "validation_data = vectorizer.transform(lyrics_val).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score naive_bayes in training: 0.4631185807656396 and alpha: 0.0\n",
      "Accuracy score naive_bayes in training: 0.5032679738562091 and alpha: 1.0\n",
      "final Accuracy score naive_bayes on test data = 0.4962962962962963\n",
      "final Accuracy score naive_bayes on training data = 0.6742919389978214\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'var_smoothing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-88f293314297>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0malpha_rate_big\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_done\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mgnb_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpriors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_smoothing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mgnb_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_tfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenre_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mpredictions_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgnb_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'var_smoothing'"
     ]
    }
   ],
   "source": [
    "# Classification using LogisticRegression\n",
    "not_done = True\n",
    "acc_old = 0\n",
    "acc_new = 0\n",
    "alpha = 0.\n",
    "alpha_rate_small = 1.\n",
    "alpha_rate_big = 3.\n",
    "while(not_done):\n",
    "    naive_bayes = MultinomialNB(alpha)\n",
    "    naive_bayes.fit(train_data_tfid, genre_train)\n",
    "    predictions_val = naive_bayes.predict(validation_data)\n",
    "    acc_new = accuracy_score(genre_val, predictions_val)\n",
    "    if acc_old > acc_new:\n",
    "        alpha = alpha + alpha_rate_big\n",
    "        naive_bayes = MultinomialNB(alpha)\n",
    "        naive_bayes.fit(train_data_tfid, genre_train)\n",
    "        predictions_val = naive_bayes.predict(validation_data)\n",
    "        acc_new = accuracy_score(genre_val, predictions_val)\n",
    "        if acc_old > acc_new:\n",
    "            alpha = alpha - alpha_rate_big\n",
    "            naive_bayes = MultinomialNB(alpha)\n",
    "            naive_bayes.fit(train_data_tfid, genre_train)\n",
    "            not_done = False\n",
    "            break\n",
    "    acc_old = acc_new\n",
    "    print('Accuracy score naive_bayes in training: {} and alpha: {}'.format(acc_old, alpha))\n",
    "    alpha = alpha + alpha_rate_small\n",
    "        \n",
    "predictions1 = naive_bayes.predict(test_data)\n",
    "print('final Accuracy score naive_bayes on test data = {}'.format(accuracy_score(genre_test, predictions1)))\n",
    "predictions1 = naive_bayes.predict(train_data_tfid)\n",
    "print('final Accuracy score naive_bayes on training data = {}'.format(accuracy_score(genre_train, predictions1)))\n",
    "\n",
    "not_done = True\n",
    "acc_old = 0\n",
    "acc_new = 0\n",
    "alpha = 0.\n",
    "alpha_rate_small = 1.\n",
    "alpha_rate_big = 3.\n",
    "while(not_done):\n",
    "    gnb_clf = GaussianNB(priors=None, var_smoothing=alpha)\n",
    "    gnb_clf.fit(train_data_tfid, genre_train)\n",
    "    predictions_val = gnb_clf.predict(validation_data)\n",
    "    acc_new = accuracy_score(genre_val, predictions_val)\n",
    "    if acc_old > acc_new:\n",
    "        alpha = alpha + alpha_rate_big\n",
    "        gnb_clf = GaussianNB(priors=None, var_smoothing=alpha)\n",
    "        gnb_clf.fit(train_data_tfid, genre_train)\n",
    "        predictions_val = gnb_clf.predict(validation_data)\n",
    "        acc_new = accuracy_score(genre_val, predictions_val)\n",
    "        if acc_old > acc_new:\n",
    "            alpha = alpha - alpha_rate_big\n",
    "            gnb_clf = GaussianNB(priors=None, var_smoothing=alpha)\n",
    "            gnb_clf.fit(train_data_tfid, genre_train)\n",
    "            not_done = False\n",
    "            break\n",
    "    acc_old = acc_new\n",
    "    print('Accuracy score naive_bayes gaussian in training: {} and alpha: {}'.format(acc_old, alpha))\n",
    "    alpha = alpha + alpha_rate_small\n",
    "\n",
    "predictions2 = gnb_clf.predict(test_data)\n",
    "print('Accuracy score gnb_clf on the test data = {}'.format(accuracy_score(genre_test, predictions2)))\n",
    "predictions2 = gnb_clf.predict(train_data_tfid)\n",
    "print('final Accuracy score gnb_clf on training data = {}'.format(accuracy_score(genre_train, predictions2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
